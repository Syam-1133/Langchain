
# Langchain AI Assistant Pro

Langchain AI Assistant Pro is a modular, end-to-end project demonstrating how to build advanced AI-powered applications for workplace productivity using the LangChain framework, Streamlit, and Ollama. This project covers the full pipeline from data ingestion and transformation to embedding, vector storage, and a conversational AI web app interface.

## Features

- **Conversational AI Web App**: Modern, professional chat UI built with Streamlit, supporting multiple LLMs (Gemma, Llama2, Mistral, etc.) via Ollama.
- **Customizable Prompting**: Uses LangChain's prompt templates and output parsers for flexible, professional AI responses.
- **Data Ingestion**: Load and process text, PDF, and other document types using LangChain document loaders.
- **Text Transformation**: Split and preprocess documents for downstream tasks (e.g., chunking, cleaning).
- **Embeddings**: Generate vector representations of text using OpenAI, HuggingFace, or Ollama embeddings.
- **Vector Stores**: Store and search embeddings efficiently using ChromaDB and Faiss.
- **Modular Notebooks**: Each stage of the pipeline is demonstrated in a dedicated Jupyter notebook for easy learning and experimentation.
- **Environment Management**: Uses `python-dotenv` for secure API key and environment variable management.

## Project Structure

```
LANGCHAIN/
├── 1-OpenAI/                # Quickstart with LangChain and OpenAI (notebooks)
├── 2-ollama/                # Streamlit web app with Ollama LLM integration
├── 3.2 - Dataingestion/     # Data ingestion loaders and demos
├── 3.3 - Data transformation/ # Text splitting and transformation
├── 4.Embeding/              # Embedding techniques and demos
├── 5- vectorstore/          # Vector database (Chroma, Faiss) demos
├── syam.py                  # (Reserved for custom scripts)
requirements.txt             # Python dependencies
README.md                    # Project documentation
```

## Key Components

### 1. Conversational AI Web App (`2-ollama/app.py`)
- Built with Streamlit for a beautiful, interactive chat experience.
- Integrates Ollama LLMs via LangChain for local or cloud-based inference.
- Sidebar for model selection, temperature control, and chat management.
- Tracks conversation history and usage statistics.
- Custom CSS for a seamless, modern look.

#### Detailed Explanation: `2-ollama/app.py`

This is a full-featured conversational AI assistant web app, designed for productivity and professional use. Here’s how it works and what makes it special:

**Architecture & Flow:**

- Uses Streamlit for the UI, providing a modern, responsive chat interface with custom CSS for a polished look.
- Loads environment variables securely using `python-dotenv` for API keys and project settings.
- Integrates with Ollama LLMs (e.g., Gemma, Llama2, Mistral) via the `langchain_ollama` package, allowing you to run powerful language models locally or in the cloud.
- Uses LangChain’s `ChatPromptTemplate` and `StrOutputParser` to structure prompts and parse model outputs.
- Maintains chat history in Streamlit’s session state, so the conversation persists across interactions.
- Sidebar allows users to:
	- Select the AI model (Gemma, Llama2, Mistral, etc.)
	- Adjust response creativity (temperature)
	- View chat statistics (total chats, today’s chats)
	- Clear the conversation with one click
- Main area displays:
	- Welcome message for new users
	- Live chat conversation with user and AI message bubbles, including avatars
	- Input box and send button for new messages
- When a user sends a message:
	- The message is added to the chat history
	- The app shows a spinner while the AI is generating a response
	- The AI response is generated by invoking the LangChain chain with the user’s question
	- The response is added to the chat and the UI is refreshed
	- If there’s an error, a friendly error message is shown
- Footer displays project credits

**Customization & Extensibility:**

- Easily switch between different LLMs and adjust their parameters
- All UI elements are styled for a seamless, professional appearance
- Modular code structure makes it easy to extend with new features, models, or integrations

**Usage:**

Run the app with:

```bash
streamlit run LANGCHAIN/2-ollama/app.py
```

Then open the provided local URL in your browser to interact with your AI assistant.

This app is ideal as a starting point for building your own enterprise AI chatbots, productivity tools, or as a demo for LangChain + Ollama capabilities.

### 2. Data Ingestion & Transformation
- **Dataingestion.ipynb**: Demonstrates loading text and PDF documents using LangChain loaders.
- **textsplitter.ipynb**: Shows how to split documents into manageable chunks for embedding and retrieval.

### 3. Embedding & Vector Storage
- **embeding.ipynb**: Explains embedding techniques using OpenAI, HuggingFace, and Ollama.
- **Chroma.ipynb / Faiss.ipynb**: Demonstrates storing and searching embeddings in ChromaDB and Faiss vector stores.

## How to Run

1. **Clone the repository** and navigate to the project folder.
2. **Set up a Python environment** (recommended: Python 3.10+ and `venv` or `conda`).
3. **Install dependencies:**
	```bash
	pip install -r requirements.txt
	```
4. **Configure environment variables:**
	- Create a `.env` file with your API keys (OpenAI, LangChain, etc.) as needed.
5. **Run the Streamlit app:**
	```bash
	streamlit run LANGCHAIN/2-ollama/app.py
	```
6. **Explore the notebooks** for step-by-step guides on each pipeline stage.

## Requirements

- Python 3.10+
- See `requirements.txt` for all Python dependencies
- Ollama (for local LLMs): https://ollama.com/

## Example Use Cases

- Build your own AI chat assistant for enterprise or personal productivity
- Experiment with document ingestion, chunking, and retrieval-augmented generation (RAG)
- Learn how to use vector databases for semantic search
- Customize and extend with your own data, models, or UI

## Credits

- Built with [LangChain](https://python.langchain.com/), [Streamlit](https://streamlit.io/), [Ollama](https://ollama.com/), [ChromaDB](https://www.trychroma.com/), [Faiss](https://github.com/facebookresearch/faiss), and more.

---

© 2024 AI Assistant Pro • Built with Streamlit & Ollama
